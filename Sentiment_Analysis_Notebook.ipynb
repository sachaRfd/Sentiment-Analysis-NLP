{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sachaRfd/Sentiment-Analysis-NLP/blob/main/Sentiment_Analysis_Notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Simple Sentiment Analysis using IMDB PyTorch Dataset and simple LSTM:"
      ],
      "metadata": {
        "id": "bvm1VVTO4xsl"
      },
      "id": "bvm1VVTO4xsl"
    },
    {
      "cell_type": "markdown",
      "source": [
        "All Imports:"
      ],
      "metadata": {
        "id": "6zk3XNbt4_kI"
      },
      "id": "6zk3XNbt4_kI"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchdata  # Install Torch Datasets\n",
        "!pip install nltk  #  Import the Natural Language Toolkit --> Most Common\n",
        "\n",
        "import nltk  # Download key files\n",
        "nltk.download('punkt')  # Sequence Tokeniser\n",
        "nltk.download('stopwords')  # List of Most Common StopWords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords \n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import string \n",
        "\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import gc\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn.functional import pad\n",
        "import torch.nn.functional as F\n",
        "from torchtext.data import to_map_style_dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.optim import RMSprop\n",
        "\n",
        "\n",
        "# Set Device to GPU is available - otherwise set to CPU: \n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'Your Current Device is {device}')  # Check the Colab Device we are using\n",
        "\n",
        "from torchtext import data, datasets  # Import the datasets\n",
        "from sklearn.model_selection import train_test_split  # Import splitting function\n",
        "from sklearn.metrics import accuracy_score\n",
        "import torchdata\n",
        "\n",
        "from torchtext.vocab import GloVe  # Import the Glove Embedding"
      ],
      "metadata": {
        "id": "IdJSwr7e4-4-"
      },
      "id": "IdJSwr7e4-4-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's get the Train, Validation and Training Sets ready: "
      ],
      "metadata": {
        "id": "3StZWGLJ64ht"
      },
      "id": "3StZWGLJ64ht"
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the train and test splits form the IMDB Dataset\n",
        "train_dataset, test_dataset  = datasets.IMDB(root = '.data', split = ('train', 'test'))\n",
        "\n",
        "# Let's now split the test set into a test and validation set: \n",
        "test_dataset, valid_dataset = train_test_split(list(test_dataset), train_size=.8)\n"
      ],
      "metadata": {
        "id": "J_uRE7P26-JJ"
      },
      "id": "J_uRE7P26-JJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The Dataset: \n",
        "IMDB Reviews\n"
      ],
      "metadata": {
        "id": "fXfE-9e56_QH"
      },
      "id": "fXfE-9e56_QH"
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'The shape of the training set is {train_dataset.shape}')"
      ],
      "metadata": {
        "id": "ObXgtrWG7Yrd"
      },
      "id": "ObXgtrWG7Yrd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Shape of the Dataset is XXX. \n",
        "\n",
        "Let's Check if our data is balanced in training: "
      ],
      "metadata": {
        "id": "PwZZaanj7sKH"
      },
      "id": "PwZZaanj7sKH"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OSQ0AsiP7vO0"
      },
      "id": "OSQ0AsiP7vO0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Let's now visualise some of the reviews: "
      ],
      "metadata": {
        "id": "0I7jEXXh7Vvk"
      },
      "id": "0I7jEXXh7Vvk"
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset[:3]"
      ],
      "metadata": {
        "id": "0sTYA9Tg7ElX"
      },
      "id": "0sTYA9Tg7ElX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The "
      ],
      "metadata": {
        "id": "fTsu999e7Khe"
      },
      "id": "fTsu999e7Khe"
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}